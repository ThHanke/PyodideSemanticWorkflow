# CSVW Column Average Workflow Guide

This guide explains how to use and execute the CSVW Column Average two-step workflow.

## Overview

The CSVW Column Average workflow demonstrates a multi-step data processing pipeline:

1. **Step 1: Load Column** - Reads a column from a CSV file using CSVW metadata
2. **Step 2: Calculate Average** - Computes the arithmetic mean of the loaded values

This workflow showcases:
- Multi-step workflow composition
- Data flow between steps
- CSVW metadata integration
- Unit preservation through processing steps
- Separate Python implementations with different dependencies

## Workflow Structure

### Template Definition

From `workflows/catalog.ttl`:

```turtle
spw:CSVWAverageTemplate a p-plan:Plan, prov:Plan ;
    rdfs:label "CSVW Column Average"@en ;
    schema:category "Data Processing" .

# Step 1
spw:LoadCSVWColumnStep a p-plan:Step ;
    p-plan:isStepOfPlan spw:CSVWAverageTemplate ;
    prov:used spw:LoadCSVWColumnCode, spw:LoadCSVWColumnRequirements .

# Step 2  
spw:CalculateAverageStep a p-plan:Step ;
    p-plan:isStepOfPlan spw:CSVWAverageTemplate ;
    prov:used spw:CalculateAverageCode, spw:CalculateAverageRequirements .
```

### Variables

**Step 1 Inputs:**
- `spw:CSVWMetadataURI` - URI of the CSVW metadata JSON file
- `spw:CSVWColumnName` - Name of the column to load

**Step 1 Output:**
- `spw:LoadedColumnData` - Collection of values from the column

**Step 2 Input:**
- `spw:AverageInputCollection` - Collection (from Step 1)

**Step 2 Output:**
- `spw:AverageOutput` - Average as QUDT QuantityValue

## Generating Activity Instances

### Step 1: Load Column from CSVW

#### 1. Create Input Entities

```turtle
# Metadata URI input
spw:metadataURIInput_20260202_001 a prov:Entity ;
    rdf:value "https://example.com/data-metadata.json"^^xsd:anyURI ;
    p-plan:correspondsToVariable spw:CSVWMetadataURI ;
    rdfs:label "CSVW Metadata URI"@en .

# Column name input
spw:columnNameInput_20260202_001 a prov:Entity ;
    rdf:value "temperature"^^xsd:string ;
    p-plan:correspondsToVariable spw:CSVWColumnName ;
    rdfs:label "Column name"@en .
```

#### 2. Create Activity

```turtle
spw:LoadColumnRun_20260202_001 a prov:Activity ;
    # Links to template
    prov:hadPlan spw:CSVWAverageTemplate ;
    p-plan:correspondsToStep spw:LoadCSVWColumnStep ;
    
    # Inherited resources from Step
    prov:used spw:LoadCSVWColumnCode, spw:LoadCSVWColumnRequirements ;
    
    # Concrete input data
    prov:used spw:metadataURIInput_20260202_001, spw:columnNameInput_20260202_001 ;
    
    # Agent and timing
    prov:wasAssociatedWith spw:PyodideEngine ;
    prov:startedAtTime "2026-02-02T11:00:00Z"^^xsd:dateTime ;
    prov:endedAtTime "2026-02-02T11:00:02Z"^^xsd:dateTime .

# BFO-style input links (for Python script)
spw:metadataURIInput_20260202_001 bfo:is_input_of spw:LoadColumnRun_20260202_001 .
spw:columnNameInput_20260202_001 bfo:is_input_of spw:LoadColumnRun_20260202_001 .
```

#### 3. Generate Output (Executed by Python)

The `load_csvw_column.py` script generates:

```turtle
<#loadedColumnData_hash123> a prov:Entity, prov:Collection ;
    p-plan:correspondsToVariable spw:LoadedColumnData ;
    rdfs:label "Column data: Temperature"@en ;
    prov:wasGeneratedBy spw:LoadColumnRun_20260202_001 ;
    prov:wasDerivedFrom spw:metadataURIInput_20260202_001, spw:columnNameInput_20260202_001 ;
    
    # Metadata
    qudt:unit unit:DEG_C ;
    spw:sourceColumn "temperature" ;
    spw:columnTitle "Temperature" ;
    spw:valueCount "5"^^xsd:integer .

# Individual values
<#value0_hash123> a qudt:QuantityValue ;
    qudt:numericValue "23.5"^^xsd:decimal ;
    qudt:unit unit:DEG_C .

<#loadedColumnData_hash123> prov:hadMember <#value0_hash123>, ... .
```

### Step 2: Calculate Average

#### 1. Use Output from Step 1 as Input

The collection generated by Step 1 becomes the input:

```turtle
spw:CalculateAverageRun_20260202_001 a prov:Activity ;
    # Links to template
    prov:hadPlan spw:CSVWAverageTemplate ;
    p-plan:correspondsToStep spw:CalculateAverageStep ;
    
    # Inherited resources from Step
    prov:used spw:CalculateAverageCode, spw:CalculateAverageRequirements ;
    
    # Use output from Step 1
    prov:used <#loadedColumnData_hash123> ;
    
    # Link to previous activity
    prov:wasInformedBy spw:LoadColumnRun_20260202_001 ;
    
    # Agent and timing
    prov:wasAssociatedWith spw:PyodideEngine ;
    prov:startedAtTime "2026-02-02T11:00:02Z"^^xsd:dateTime ;
    prov:endedAtTime "2026-02-02T11:00:03Z"^^xsd:dateTime .

# BFO-style input link
<#loadedColumnData_hash123> bfo:is_input_of spw:CalculateAverageRun_20260202_001 .
```

#### 2. Generate Final Output (Executed by Python)

The `calculate_average.py` script generates:

```turtle
<#averageResult_hash456> a qudt:QuantityValue, prov:Entity ;
    p-plan:correspondsToVariable spw:AverageOutput ;
    rdfs:label "Average of 5 values"@en ;
    
    # Result value with unit
    qudt:numericValue "23.5"^^xsd:decimal ;
    qudt:unit unit:DEG_C ;
    
    # Provenance
    prov:wasGeneratedBy spw:CalculateAverageRun_20260202_001 ;
    prov:wasDerivedFrom <#loadedColumnData_hash123> ;
    
    # Additional metadata
    spw:valueCount "5"^^xsd:integer ;
    spw:calculationMethod "arithmetic mean" ;
    spw:minValue "22.9"^^xsd:decimal ;
    spw:maxValue "24.1"^^xsd:decimal .
```

## CSVW Metadata Requirements

The CSVW metadata file must follow this structure:

```json
{
  "@context": "http://www.w3.org/ns/csvw",
  "url": "data.csv",
  "tableSchema": {
    "columns": [
      {
        "name": "column_name",
        "titles": "Column Title",
        "datatype": "number",
        "dc:unit": "°C"
      }
    ]
  }
}
```

### Unit Mapping

The `load_csvw_column.py` script maps common unit notations to QUDT:

- `mm`, `millimeter` → `unit:MilliM`
- `m`, `meter` → `unit:M`
- `cm`, `centimeter` → `unit:CentiM`
- `°C`, `celsius` → `unit:DEG_C`
- `K`, `kelvin` → `unit:K`
- `kg`, `kilogram` → `unit:KiloGM`
- `g`, `gram` → `unit:GM`

## Python Implementation Details

### Step 1: load_csvw_column.py

**Dependencies:** `rdflib==7.0.0`, `requests==2.31.0`

**Algorithm:**
1. Parse CSVW metadata from URI
2. Extract column schema and unit information
3. Download CSV file
4. Extract column values
5. Map units to QUDT
6. Create Collection of QuantityValues
7. Return RDF graph

**Key Functions:**
- `parse_csvw_metadata(uri)` - Fetch and parse JSON
- `map_csvw_unit_to_qudt(unit)` - Unit conversion
- `load_column_from_csvw(uri, column)` - Main loading logic

### Step 2: calculate_average.py

**Dependencies:** `rdflib==7.0.0`

**Algorithm:**
1. Find input Collection
2. Extract all members
3. Get numeric values and units
4. Validate unit consistency
5. Calculate mean using `statistics.mean()`
6. Generate QuantityValue with metadata
7. Return RDF graph

**Key Functions:**
- Standard provenance helpers (inherited pattern)
- Statistical calculation using Python's `statistics` module

## Error Handling

Both scripts use Web Annotations for errors:

```turtle
<#errorAnn_hash> a oa:Annotation ;
    oa:motivatedBy ex:errorReporting ;
    oa:hasTarget ?activity ;
    oa:hasBody [
        a oa:TextualBody ;
        rdf:value "Error message"^^xsd:string ;
        ex:errorCode "ERROR_CODE"
    ] ;
    prov:wasGeneratedBy ?activity .
```

### Common Error Codes

**Step 1:**
- `PARSE_ERROR` - Failed to parse input graph
- `INPUT_TOO_FEW` - Missing required inputs
- `MISSING_INPUT` - Could not determine metadata URI or column name
- `CSVW_LOAD_ERROR` - Failed to load from CSVW

**Step 2:**
- `INPUT_TOO_FEW` - No collection provided
- `EMPTY_COLLECTION` - Collection has no members
- `MISSING_NUMERIC_VALUE` - Member missing value
- `NON_NUMERIC_VALUE` - Value not numeric
- `UNIT_MISMATCH` - Inconsistent units
- `CALCULATION_ERROR` - Failed to calculate mean

## Example Usage

See `examples/csvw-average-execution.ttl` for a complete working example using the Mat-O-Lab CSVToCSVW example metadata.

### SPARQL Query: Find Workflow Execution

```sparql
PREFIX prov: <http://www.w3.org/ns/prov#>
PREFIX p-plan: <http://purl.org/net/p-plan#>

SELECT ?step1 ?step2 ?collection ?result
WHERE {
    # Find both activities in the workflow
    ?step1 p-plan:correspondsToStep spw:LoadCSVWColumnStep .
    ?step2 p-plan:correspondsToStep spw:CalculateAverageStep ;
           prov:wasInformedBy ?step1 .
    
    # Find the intermediate collection
    ?collection prov:wasGeneratedBy ?step1 ;
                p-plan:correspondsToVariable spw:LoadedColumnData .
    
    # Find the final result
    ?result prov:wasGeneratedBy ?step2 ;
            p-plan:correspondsToVariable spw:AverageOutput .
}
```

## Best Practices

1. **Use unique activity IDs** - Include timestamps or UUIDs
2. **Link steps explicitly** - Use `prov:wasInformedBy`
3. **Preserve units** - Always include QUDT units when available
4. **Complete provenance** - Link all inputs with `prov:wasDerivedFrom`
5. **Include metadata** - Add counts, min/max, column names
6. **Handle errors gracefully** - Use Web Annotations pattern

## Integration with React Flow UI

The workflow has UI metadata in `workflows/catalog-ui.ttl`:

- **Icon:** Table/layers icon
- **Color:** Purple (#9C27B0)
- **Category:** Data Processing
- **Node size:** 220×100 px (larger for two-step workflow)

This enables drag-and-drop visual workflow composition.

## Further Reading

- [CSVW Primer](https://www.w3.org/TR/tabular-data-primer/)
- [Mat-O-Lab CSVToCSVW](https://github.com/Mat-O-Lab/CSVToCSVW)
- [PROV-O Documentation](https://www.w3.org/TR/prov-o/)
- [Execution Generation Rules](EXECUTION_GENERATION_RULES.md)
